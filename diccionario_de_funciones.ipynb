{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LLAMAR LAS VARIABLES CON PRINT\n",
        "Ejemplo: print(histograma)"
      ],
      "metadata": {
        "id": "cB5kME1q4HD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering\n",
        "1. Missing data\n",
        "2. Feature Normalization\n",
        "3. Categorical Encoding\n",
        "4. Transformations\n",
        "5. Discretization\n",
        "6. Outliers\n",
        "7. Optional: Date and Time"
      ],
      "metadata": {
        "id": "b1zicRyo_uUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (boxplot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "2hExCQ1xZhc5",
        "outputId": "6081591d-1622-44e5-a52c-a903dcc0fa4a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-596e651e4728>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'boxplot' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Missing data (NOMBRES DE LAS VARIABLES)\n",
        "1. **cargar_datos** : carga los datos del csv\n",
        "2. **copia_df** : crea una copia del df principal\n",
        "3. **conteo_nulos** : cuenta la cantidad de nulos por columna \"feature\"\n",
        "4. **porcentaje_sin_nulos** : porcentaje de datos sin valores faltantes\n",
        "5. **porcentaje_de_faltantes** : resumen de la proporción de valores faltantes en cada columna\n",
        "6. **encabezado** : imprimirá las primeras 5 filas del dataframe\n",
        "7. **informacion** : proporciona información sobre un DataFrame\n",
        "8. **histograma** : muestra el histograma con estadisticos\n",
        "**histograma_comparativo__normalizado** : despues de normalizar se puede visualizar los cambios con este codigo, en este caso se normalizo con minmaxscaler y standardscaler\n",
        "9. **tabla_de_frecuencia** : imprime una tabla con el contenido y cuantas veces aparece en la columna\n",
        "10. **grafico_de_densidad**: visual de la distribución de probabilidad de una variable continua con estadisticos\n",
        "11. **grafico_densidad_varios_grupos** : visual de la distribución de probabilidad de varias variables continuas a la vez con estadisticos\n",
        "12. **Grafico_de_barras** : Cuenta la frecuencia de observaciones en cada categoría de la variable y utiliza los valores únicos como etiquetas de eje x\n",
        "13. **boxplot**: son útiles para detectar valores atípicos (outliers) y para comparar la distribución de los datos en diferentes grupos, pueden ayudar a identificar si una distribución es simétrica o sesgada es **necesario borrar nulos**\n",
        "14. \n",
        "15.\n",
        "16."
      ],
      "metadata": {
        "id": "bo_QwT4l3yON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cargar_datos = 'nueva_variable = pd.read_csv(\"https://direccion de donde voy a descargar el csv\") #carga un conjunto de datos de un archivo CSV ubicado en una dirección URL en la variable \"nueva_variable\". La función \"read_csv()\" se utiliza para leer un archivo CSV y crear un objeto DataFrame en pandas.'\n",
        "print(cargar_datos)\n"
      ],
      "metadata": {
        "id": "Ew7lPWrJ4c9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copia_df = 'nuevo objeto = df-del-que-se-va-a-hacer-la-copia.copy() #La copia se realiza para que podamos trabajar con los datos sin modificar el DataFrame original.'\n",
        "print (copia_df)"
      ],
      "metadata": {
        "id": "axghLgsy55or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conteo_nulos = 'dataframe.isna().sum() # cuenta la cantidad de valores faltantes en cada columna del objeto DataFrame \"sum()\" se utiliza para sumar los valores booleanos en cada columna del DataFrame resultante de la función \"isna()\".'\n",
        "print (conteo_nulos)"
      ],
      "metadata": {
        "id": "mtKyRnUI6dI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porcentaje_sin_nulos = \"print(f'Percentage of data without missing values: {dataframe_a_Analizar.dropna().shape[0]/ np.float(data0.shape[0])}')\\n #ahora lo voy a dividir por 100 para que aparezca el valor en porcentaje y le escribo % al final \\n print(f'Percentage of data without missing values: {100*dataframe_a_Analizar.dropna().shape[0]/data0.shape[0]:.2f}%')\"\n",
        "print (porcentaje_sin_nulos)"
      ],
      "metadata": {
        "id": "BuGhM2J18jhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porcentaje_de_faltantes = \" #obtendremos un resumen de la proporción de valores faltantes en cada columna de 'dataframe', donde la proporción se define como el número de valores faltantes dividido por el número total de valores en la columna.\\n dataframe.isna().mean() #isna()' se utiliza para verificar si cada celda contiene un valor faltante (NaN). 'mean()' se utiliza para calcular la media de los valores booleanos en cada columna del DataFrame resultante de la función 'isna()'.\"\n",
        "print (porcentaje_de_faltantes)"
      ],
      "metadata": {
        "id": "TDb_cMcg9jmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encabezado = \"print(dataframe.head()) #Esta línea de código imprimirá las primeras 5 filas del dataframe en la consola.\"\n",
        "print (encabezado)"
      ],
      "metadata": {
        "id": "s2XWJglv-guv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "informacion = \"# resumen de información sobre el objeto DataFrame, El resumen incluirá el número total de filas y columnas en el DataFrame, el nombre y el tipo de dato de cada columna, la cantidad de valores no nulos en cada columna, y una estimación de la cantidad de memoria utilizada por el objeto DataFrame. \\n dataframe.info()\"\n",
        "print (informacion)"
      ],
      "metadata": {
        "id": "pRUFRGfr_Is-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "histograma = \"LEER BIEN LAS INSTRUCCIONES quitar los espacios entre \\ 033 lineas 52,54,60,62 \\n\\\n",
        "# ejemplo de histograma de la variable de edad del df data1 utilizando la biblioteca de visualización de datos Matplotlib. \\n\\\n",
        "# en este caso se imprimen los estadisticos basicos en un print y lineas dentro del grafico con la media y la mediana\\n\\\n",
        "import numpy as np\\n\\\n",
        "import matplotlib.pyplot as plt\\n\\\n",
        "\\n\\\n",
        "# Crea el histograma de la variable Age.\\n\\\n",
        "plt.hist(data1['Age'], bins=20)\\n\\\n",
        "\\n\\\n",
        "# Calcula la media, la mediana, el coeficiente de asimetría, el rango intercuartil y la desviación estándar de la variable Age.\\n\\\n",
        "age_mean = data1['Age'].mean()\\n\\\n",
        "age_median = data1['Age'].median()\\n\\\n",
        "age_skewness = data1['Age'].skew()\\n\\\n",
        "age_iqr = data1['Age'].quantile(0.75) - data1['Age'].quantile(0.25)\\n\\\n",
        "age_std = data1['Age'].std()\\n\\\n",
        "\\n\\\n",
        "# Calcula los cuartiles para determinar si los valores están concentrados cerca de la mediana.\\n\\\n",
        "age_q1 = data1['Age'].quantile(0.25)\\n\\\n",
        "age_q3 = data1['Age'].quantile(0.75)\\n\\\n",
        "\\n\\\n",
        "# Agrega líneas verticales para la media y la mediana.\\n\\\n",
        "plt.axvline(age_mean, color='r', linestyle='--', label=f'Mean: {age_mean:.2f}')\\n\\\n",
        "plt.axvline(age_median, color='b', linestyle='--', label=f'Median: {age_median:.2f}')\\n\\\n",
        "\\n\\\n",
        "# Agrega una etiqueta para la media y la mediana.\\n\\\n",
        "plt.text(age_mean + 1, 60, f'Mean: {age_mean:.2f}', rotation=90, color='r')\\n\\\n",
        "plt.text(age_median + 1, 55, f'Median: {age_median:.2f}', rotation=90, color='b')\\n\\\n",
        "\\n\\\n",
        "# Agrega estadísticas básicas en la parte inferior de la gráfica.\\n\\\n",
        "age_stats = data1['Age'].describe()\\n\\\n",
        "age_stats['Skewness/asimetría'] = age_skewness\\n\\\n",
        "age_stats['Std'] = age_std\\n\\\n",
        "plt.text(0.01, -0.3, age_stats.to_string(), transform=plt.gca().transAxes, fontsize=10, verticalalignment='top')\\n\\\n",
        "\\n\\\n",
        "# Etiqueta el eje x como Age.\\n\\\n",
        "plt.xlabel('Age')\\n\\\n",
        "\\n\\\n",
        "# Etiqueta el eje y como Frequency.\\n\\\n",
        "plt.ylabel('Frequency')\\n\\\n",
        "\\n\\\n",
        "# Establece los límites del eje y en 0 y 100 y la ubicación de los ticks en incrementos de 10.\\n\\\n",
        "plt.yticks(range(0, 100, 10))\\n\\\n",
        "\\n\\\n",
        "# Establece los límites del eje x en 0 y 90 y la ubicación de los ticks cada 5.\\n\\\n",
        "plt.xticks(range(0, 90, 5))\\n\\\n",
        "\\n\\\n",
        "# Agrega una leyenda con las etiquetas y los valores de la media y la mediana.\\n\\\n",
        "plt.legend()\\n\\\n",
        "\\n\\\n",
        "# Determina si la distribución está sesgada y en qué dirección.\\n\\\n",
        "if age_mean > age_median:\\n\\\n",
        "    print('\\ 033[91m' + 'La distribución está sesgada a la derecha' + '\\ 033[0m')\\n\\\n",
        "elif age_mean < age_median:\\n\\\n",
        "    print('\\ 033[91m' + 'La distribución está sesgada a la izquierda' + '\\ 033[0m')\\n\\\n",
        "else:\\n\\\n",
        "    print('La distribución es simétrica')\\n\\\n",
        "\\n\\\n",
        "# Determina si los valores están concentrados cerca de la mediana o dispersos.\\n\\\n",
        "if age_iqr < age_median:\\n\\\n",
        "    print('\\ 033[91m' + 'Los valores están muy concentrados cerca de la mediana' + '\\ 033[0m')\\n\\\n",
        "else:\\n\\\n",
        "    print('\\ 033[91m' + 'Los valores están dispersos' + '\\ 033[0m')\\n\\\n",
        "\\n\\\n",
        "#Muestra el histograma en la pantalla.\\n\\\n",
        "plt.show()\"\n",
        "\n",
        "print(histograma)"
      ],
      "metadata": {
        "id": "k5l5h4qEDkpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "histograma_comparativo__normalizado = \"import numpy as np \\n\\\n",
        "import matplotlib.pyplot as plt\\n\\\n",
        "\\n\\\n",
        "# Crea una figura con tres subplots, cada uno para un histograma de la variable Age.\\n\\\n",
        "fig, ax = plt.subplots(1, 3, figsize=(12, 4)) #crea una figura con una fila y tres columnas de subgráficos (1 fila y 3 columnas)tamaño 12 pulg ancho y 4 pulg alto.\\n\\\n",
        "#El resultado de esta línea es una tupla que contiene la figura y los ejes de los subgráficos en un arreglo de numpy. Esta tupla es desempaquetada en las variables fig y ax mediante la asignación múltiple.\\n\\\n",
        "\\n\\\n",
        "# Agregar información de asimetría y concentración de valores en los subplots\\n\\\n",
        "cambiar a comillas dobles f'Asymmetry: {age_skewness:.2f}'\\n\\\n",
        "ax[0].text(0.1, 1.1, f'Asymmetry: {age_skewness:.2f}', transform=ax[0].transAxes)#text(0.1, 1.1, ACA SE CAMBIA LA POSICION DEL TEXTO EN EL GRAFICO\\n\\\n",
        "if age_iqr < age_median:\\n\\\n",
        "cambiar a comillas dobles 'Value concentration: high'\\n\\\n",
        "    ax[0].text(0.1, 1.15, 'Value concentration: high', transform=ax[0].transAxes) #text(0.1, 1.15, ACA SE CAMBIA LA POSICION DEL TEXTO EN EL GRAFICO\\n\\\n",
        "else:\\n\\\n",
        "cambiar a comillas dobles 'Value concentration: low'\\n\\\n",
        "    ax[0].text(0.1, 1.15, 'Value concentration: low', transform=ax[0].transAxes) #text(0.1, 1.15, ACA SE CAMBIA LA POSICION DEL TEXTO EN EL GRAFICO\\n\\\n",
        "\\n\\\n",
        "\\n\\\n",
        "# Histograma original\\n\\\n",
        "ax[0].hist(data2['Age'], bins=20) #histograma de Age en el primer eje del gráfico.bins o intervalos para agrupar los datos en el histograma, en este caso 20.\\n\\\n",
        "ax[0].set_title('Original Age')\\n\\\n",
        "\\n\\\n",
        "# Histograma MinMaxScaler\\n\\\n",
        "ax[1].hist(data2['Age_MinMax'], bins=20) #histograma de Age en el SEGUNDO eje del gráfico.bins o intervalos para agrupar los datos en el histograma, en este caso 20.\\n\\\n",
        "ax[1].set_title('MinMaxScaler Age')\\n\\\n",
        "ax[1].legend(['MinMaxScaler'], loc='upper right')\\n\\\n",
        "\\n\\\n",
        "# Histograma StandardScaler\\n\\\n",
        "ax[2].hist(data2['Age_Standard'], bins=20)\\n\\\n",
        "ax[2].set_title('StandardScaler Age')\\n\\\n",
        "ax[2].legend(['StandardScaler'], loc='upper right')\\n\\\n",
        "\\n\\\n",
        "# Agregar estadísticas básicas en la parte inferior del gráfico\\n\\\n",
        "age_stats = data2['Age'].describe()\\n\\\n",
        "age_stats['Skewness/asimetria'] = age_skewness\\n\\\n",
        "age_stats['Std'] = age_std\\n\\\n",
        "ax[0].text(0.01, -0.3, age_stats.to_string(), transform=ax[0].transAxes, fontsize=10, verticalalignment='top')\\n\\\n",
        "\\n\\\n",
        "# Determinar si la distribución está sesgada y en qué dirección\\n\\\n",
        "if age_mean > age_median:\\n\\\n",
        "    print('\\033[91m' + 'La distribución está sesgada a la derecha' + '\\033[0m')\\n\\\n",
        "elif age_mean < age_median:\\n\\\n",
        "    print('\\033[91m' + 'La distribución está sesgada a la izquierda' + '\\033[0m')\\n\\\n",
        "else:\\n\\\n",
        "    print('La distribución es simétrica')\\n\\\n",
        "\\n\\\n",
        "# Determinar si los valores están concentrados cerca de la mediana o dispersos\\n\\\n",
        "if age_iqr < age_median:\\n\\\n",
        "    print('\\033[91m' + 'Los valores están muy concentrados cerca de la mediana' + '\\033[0m')\\n\\\n",
        "else:\\n\\\n",
        "    print('\\033[91m' + 'Los valores están dispersos' + '\\033[0m')\\n\\\n",
        "\\n\\\n",
        "# Mostrar el histograma en la pantalla\\n\\\n",
        "plt.show()\"\n",
        "print (histograma_comparativo__normalizado)"
      ],
      "metadata": {
        "id": "U3unQz9NOgAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef5a377a-5bf0-471a-d136-e614e07b019e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import numpy as np \n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# Crea una figura con tres subplots, cada uno para un histograma de la variable Age.\n",
            "fig, ax = plt.subplots(1, 3, figsize=(12, 4)) #crea una figura con una fila y tres columnas de subgráficos (1 fila y 3 columnas)tamaño 12 pulg ancho y 4 pulg alto.\n",
            "#El resultado de esta línea es una tupla que contiene la figura y los ejes de los subgráficos en un arreglo de numpy. Esta tupla es desempaquetada en las variables fig y ax mediante la asignación múltiple.\n",
            "\n",
            "# Agregar información de asimetría y concentración de valores en los subplots\n",
            "cambiar a comillas dobles f'Asymmetry: {age_skewness:.2f}'\n",
            "ax[0].text(0.1, 1.1, f'Asymmetry: {age_skewness:.2f}', transform=ax[0].transAxes)#text(0.1, 1.1, ACA SE CAMBIA LA POSICION DEL TEXTO EN EL GRAFICO\n",
            "if age_iqr < age_median:\n",
            "cambiar a comillas dobles 'Value concentration: high'\n",
            "    ax[0].text(0.1, 1.15, 'Value concentration: high', transform=ax[0].transAxes) #text(0.1, 1.15, ACA SE CAMBIA LA POSICION DEL TEXTO EN EL GRAFICO\n",
            "else:\n",
            "cambiar a comillas dobles 'Value concentration: low'\n",
            "    ax[0].text(0.1, 1.15, 'Value concentration: low', transform=ax[0].transAxes) #text(0.1, 1.15, ACA SE CAMBIA LA POSICION DEL TEXTO EN EL GRAFICO\n",
            "\n",
            "\n",
            "# Histograma original\n",
            "ax[0].hist(data2['Age'], bins=20) #histograma de Age en el primer eje del gráfico.bins o intervalos para agrupar los datos en el histograma, en este caso 20.\n",
            "ax[0].set_title('Original Age')\n",
            "\n",
            "# Histograma MinMaxScaler\n",
            "ax[1].hist(data2['Age_MinMax'], bins=20) #histograma de Age en el SEGUNDO eje del gráfico.bins o intervalos para agrupar los datos en el histograma, en este caso 20.\n",
            "ax[1].set_title('MinMaxScaler Age')\n",
            "ax[1].legend(['MinMaxScaler'], loc='upper right')\n",
            "\n",
            "# Histograma StandardScaler\n",
            "ax[2].hist(data2['Age_Standard'], bins=20)\n",
            "ax[2].set_title('StandardScaler Age')\n",
            "ax[2].legend(['StandardScaler'], loc='upper right')\n",
            "\n",
            "# Agregar estadísticas básicas en la parte inferior del gráfico\n",
            "age_stats = data2['Age'].describe()\n",
            "age_stats['Skewness/asimetria'] = age_skewness\n",
            "age_stats['Std'] = age_std\n",
            "ax[0].text(0.01, -0.3, age_stats.to_string(), transform=ax[0].transAxes, fontsize=10, verticalalignment='top')\n",
            "\n",
            "# Determinar si la distribución está sesgada y en qué dirección\n",
            "if age_mean > age_median:\n",
            "    print('\u001b[91m' + 'La distribución está sesgada a la derecha' + '\u001b[0m')\n",
            "elif age_mean < age_median:\n",
            "    print('\u001b[91m' + 'La distribución está sesgada a la izquierda' + '\u001b[0m')\n",
            "else:\n",
            "    print('La distribución es simétrica')\n",
            "\n",
            "# Determinar si los valores están concentrados cerca de la mediana o dispersos\n",
            "if age_iqr < age_median:\n",
            "    print('\u001b[91m' + 'Los valores están muy concentrados cerca de la mediana' + '\u001b[0m')\n",
            "else:\n",
            "    print('\u001b[91m' + 'Los valores están dispersos' + '\u001b[0m')\n",
            "\n",
            "# Mostrar el histograma en la pantalla\n",
            "plt.show()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tabla_de_frecuencia = \"# imprime una tabla con el contenido y cuantas veces aparece en la columna \\n print(dataframe['feature'].value_counts())\"\n",
        "\n",
        "print (tabla_de_frecuencia)"
      ],
      "metadata": {
        "id": "mRONwZmAF3BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grafico_de_densidad = \"LEER BIEN LAS INSTRUCCIONES DE LA ULTIMA LINEA se recomienda hacer primero una tabla de frecuencia para saber que grupos evaluar en la grafica \\n\\\n",
        "quitar los espacios entre \\ 033 lineas 37,39,45,47 toca cambiar aca f'Min y aca (0.75)') por comillas dobles tambien y quitarle los espacios a \\ n debe quedar sin ese espacio  \\n\\\n",
        "import seaborn as sns \\n\\\n",
        "import matplotlib.pyplot as plt \\n\\\n",
        "\\n\\\n",
        "# Gráfico de densidad de la variable de edad utilizando la biblioteca Seaborn. kdeplot() se utiliza para crear la curva de densidad \\n\\\n",
        "sns.kdeplot(data1['Age'], shade=True, color='blue') \\n\\\n",
        "\\n\\\n",
        "# Calcula la media, la mediana, el coeficiente de asimetría, el rango intercuartil y la desviación estándar de la variable de edad.\\n\\\n",
        "age_mean = data1['Age'].mean()\\n\\\n",
        "age_median = data1['Age'].median()\\n\\\n",
        "age_skewness = data1['Age'].skew()\\n\\\n",
        "age_iqr = data1['Age'].quantile(0.75) - data1['Age'].quantile(0.25)\\n\\\n",
        "age_std = data1['Age'].std()\\n\\\n",
        "\\n\\\n",
        "# Agrega una línea vertical para la media \\n\\\n",
        "plt.axvline(x=age_mean, color='red', linestyle='--', label=f'Mean: {age_mean:.2f}') \\n\\\n",
        "\\n\\\n",
        "# Agrega una línea vertical para la mediana \\n\\\n",
        "plt.axvline(x=age_median, color='green', linestyle='--', label=f'Median: {age_median:.2f}') \\n\\\n",
        "\\n\\\n",
        "# Agrega una leyenda para las líneas de referencia \\n\\\n",
        "plt.legend() \\n\\\n",
        "\\n\\\n",
        "# Etiqueta el eje x como Age. \\n\\\n",
        "plt.xlabel('Age')\\n\\\n",
        "\\n\\\n",
        "# Etiqueta el eje y como Density.\\n\\\n",
        "plt.ylabel('Density')\\n\\\n",
        "\\n\\\n",
        "# Calcula los cuartiles para determinar si los valores están concentrados cerca de la mediana.\\n\\\n",
        "age_q1 = data1['Age'].quantile(0.25)\\n\\\n",
        "age_q3 = data1['Age'].quantile(0.75)\\n\\\n",
        "\\n\\\n",
        "# Determina si la distribución está sesgada y en qué dirección.\\n\\\n",
        "if age_skewness > 0:\\n\\\n",
        "    print('\\ 033[91m' + 'La distribución está sesgada a la derecha' + '\\ 033[0m')\\n\\\n",
        "elif age_skewness < 0:\\n\\\n",
        "    print('\\ 033[91m' + 'La distribución está sesgada a la izquierda' + '\\ 033[0m')\\n\\\n",
        "else:\\n\\\n",
        "    print('La distribución es simétrica')\\n\\\n",
        "\\n\\\n",
        "# Determina si los valores están concentrados cerca de la mediana o dispersos.\\n\\\n",
        "if age_iqr < age_median:\\n\\\n",
        "    print('\\ 033[91m' + 'Los valores están muy concentrados cerca de la mediana' + '\\ 033[0m')\\n\\\n",
        "else:\\n\\\n",
        "    print('\\ 033[91m' + 'Los valores están dispersos' + '\\ 033[0m')\\n\\\n",
        "\\n\\\n",
        "# Muestra el gráfico de densidad en la pantalla.\\n\\\n",
        "plt.show()\\n\\\n",
        "\\n\\\n",
        "# Imprime estadísticas básicas debajo del gráfico de densidad toca cambiar aca f'Min y aca (0.75)') por comillas dobles tambien y quitarle los espacios a \\ n debe quedar sin ese espacio \\n\\\n",
        "print(f'Min: {data1['Age'].min()}\\ nMax: {data1['Age'].max()}\\ n25%: {data1['Age'].quantile(0.25)}\\ n50%: {data1['Age'].quantile(0.5)}\\ n75%: {data1['Age'].quantile(0.75)}')\"\n",
        "\n",
        "print(grafico_de_densidad)"
      ],
      "metadata": {
        "id": "WcX8iZo2E1hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grafico_densidad_varios_grupos = \"LEER BIEN LAS INSTRUCCIONES DE LA ULTIMA LINEA se recomienda hacer primero una tabla de frecuencia para saber que grupos evaluar en la grafica \\n\\\n",
        "# en este ejemplo se evaluan dos grupos (male y female), \\n\\\n",
        "# en este caso la variable 'age' se utiliza para  que sirva como eje x de la variable a evaluar en este caso 'sex' y mirar la densidad que tiene cada sexo segun la edad \\n\\\n",
        "# en este ejemplo se evaluan dos grupos (male y female), se recomienda hacer primero una tabla de frecuencia para saber que grupos evaluar en la grafica \\n\\\n",
        "# en este caso la variable 'age' se utiliza para  que sirva como eje x de la variable a evaluar en este caso 'sex' y mirar la densidad que tiene cada sexo segun la edad \\n\\\n",
        "#Los números 0.005, 0.010, 0.015, 0.020 y 0.025 son los valores en el eje y que corresponden a la densidad de probabilidad estimada por la función kdeplot en la gráfica de densidad.\\n\\\n",
        "# Estos valores indican la probabilidad por unidad de medida (en este caso la edad) de encontrar individuos con esa edad en el conjunto de datos. Por ejemplo, si la densidad de probabilidad\\n\\\n",
        "# es 0.005 para una edad de 20 años, significa que la probabilidad de encontrar una persona de 20 años en el conjunto de datos es de 0.005 por unidad de medida de edad (por ejemplo, por cada año de edad). \\n\\\n",
        "\\n\\\n",
        "# Importar librerías necesarias\\n\\\n",
        "import seaborn as sns\\n\\\n",
        "import numpy as np\\n\\\n",
        "\\n\\\n",
        "# Crea el gráfico de densidad para el grupo male.\\n\\\n",
        "sns.kdeplot(data1.loc[data1['Sex'] == 'male', 'Age'], shade=True, label='Male')\\n\\\n",
        "\\n\\\n",
        "# Crea el gráfico de densidad para el grupo female.\\n\\\n",
        "sns.kdeplot(data1.loc[data1['Sex'] == 'female', 'Age'], shade=True, label='Female')\\n\\\n",
        "\\n\\\n",
        "# Agrega una línea vertical para la media del grupo male.\\n\\\n",
        "male_mean = data1.loc[data1['Sex'] == 'male', 'Age'].mean()\\n\\\n",
        "plt.axvline(x=male_mean, color='blue', linestyle='--', label=f'Male Mean: {male_mean:.2f}')\\n\\\n",
        "\\n\\\n",
        "# Agrega una línea vertical para la mediana del grupo male.\\n\\\n",
        "male_median = data1.loc[data1['Sex'] == 'male', 'Age'].median()\\n\\\n",
        "plt.axvline(x=male_median, color='red', linestyle='--', label=f'Male Median: {male_median:.2f}')\\n\\\n",
        "\\n\\\n",
        "# Agrega una línea vertical para la media del grupo female.\\n\\\n",
        "female_mean = data1.loc[data1['Sex'] == 'female', 'Age'].mean()\\n\\\n",
        "plt.axvline(x=female_mean, color='green', linestyle='--', label=f'Female Mean: {female_mean:.2f}')\\n\\\n",
        "\\n\\\n",
        "# Agrega una línea vertical para la mediana del grupo female.\\n\\\n",
        "female_median = data1.loc[data1['Sex'] == 'female', 'Age'].median()\\n\\\n",
        "plt.axvline(x=female_median, color='purple', linestyle='--', label=f'Female Median: {female_median:.2f}')\\n\\\n",
        "\\n\\\n",
        "# Etiqueta el eje x como Age.\\n\\\n",
        "plt.xlabel('Age')\\n\\\n",
        "\\n\\\n",
        "# Etiqueta el eje y como Density.\\n\\\n",
        "plt.ylabel('Density')\\n\\\n",
        "\\n\\\n",
        "# Agrega una leyenda con las etiquetas y los valores de la media y la mediana para cada grupo.\\n\\\n",
        "plt.legend()\\n\\\n",
        "\\n\\\n",
        "# Muestra el gráfico de densidad en la pantalla.\\n\\\n",
        "plt.show()\\n\\\n",
        "\\n\\\n",
        "# Imprime las estadísticas de resumen para cada grupo debajo del gráfico.\\n\\\n",
        "print('Male Stats:')\\n\\\n",
        "print(data1.loc[data1['Sex'] == 'male', 'Age'].describe())\\n\\\n",
        "\\n\\\n",
        "# cambiar f'\\ y }') por comillas dobles y quitarle el espacio a \\ n \\n\\\n",
        "print('\\ nFemale Stats:')\\n\\\n",
        "print(data1.loc[data1['Sex'] == 'female', 'Age'].describe())\\n\\\n",
        "\"\n",
        "print (grafico_densidad_varios_grupos)\n"
      ],
      "metadata": {
        "id": "jUSaeh2kMNaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Grafico_de_barras = \"import matplotlib.pyplot as plt\\n\\\n",
        "\\n\\\n",
        "# Cuenta la frecuencia de observaciones en cada categoría de la variable 'Sex' y utiliza los valores únicos como etiquetas de eje x.\\n\\\n",
        "plt.bar(data1['Sex'].value_counts().index, data1['Sex'].value_counts())\\n\\\n",
        "\\n\\\n",
        "# Etiqueta el eje x como Sex.\\n\\\n",
        "plt.xlabel('Sex')\\n\\\n",
        "\\n\\\n",
        "# Etiqueta el eje y como Count.\\n\\\n",
        "plt.ylabel('Count')\\n\\\n",
        "\\n\\\n",
        "# Muestra el gráfico de barras en la pantalla.\\n\\\n",
        "plt.show()\\n\\\n",
        "\\n\\\n",
        "#Grafico de barras con mas informacion:\\n\\\n",
        "import matplotlib.pyplot as plt\\n\\\n",
        "\\n\\\n",
        "# Obtener los valores únicos y su conteo\\n\\\n",
        "sex_counts = data1['Sex'].value_counts()\\n\\\n",
        "\\n\\\n",
        "# Crear la gráfica de barras\\n\\\n",
        "plt.bar(sex_counts.index, sex_counts)\\n\\\n",
        "\\n\\\n",
        "# Establecer etiquetas de los ejes y título del gráfico\\n\\\n",
        "plt.xlabel('Sex')\\n\\\n",
        "plt.ylabel('Count')\\n\\\n",
        "plt.title('Distribution of Sex')\\n\\\n",
        "\\n\\\n",
        "# Establecer límites del eje y\\n\\\n",
        "plt.ylim(0, 600)\\n\\\n",
        "\\n\\\n",
        "# Definir ubicación de los ticks en el eje y\\n\\\n",
        "plt.yticks(range(0, 601, 50))\\n\\\n",
        "\\n\\\n",
        "# Mostrar el número de cada valor en la leyenda\\n\\\n",
        "for i, v in enumerate(sex_counts):\\n\\\n",
        "    plt.text(i, v + 20, str(v), color='blue', fontweight='bold', ha='center')\\n\\\n",
        "i representa la posición de la barra en el eje x, v + 20 es la posición del texto en el eje y, se le suma 20 para que el texto aparezca arriba de la barra.\\n\\\n",
        "str(v) convierte el valor de la altura de la barra en un string. color='blue' establece el color del texto en azul. fontweight='bold' establece el estilo de la fuente como negrita.\\n\\\n",
        "ha='center' establece la alineación horizontal del texto en el centro de la barra.\\n\\\n",
        "plt.show()\"\n",
        "print(Grafico_de_barras)"
      ],
      "metadata": {
        "id": "QbDnYRsrF9to"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boxplot = \"LEER BIEN LAS INSTRUCCIONES DE LA ULTIMA LINEA quitar el espacio entre el \\ y 0 en \\ 033 en lineas 42, 44, 57, 59 para plotear en rojo \\n\\\n",
        "import matplotlib.pyplot as plt \\n\\\n",
        "\\n\\\n",
        "# Verificar si hay valores faltantes en la columna Age\\n\\\n",
        "print('valores faltantes: ', data1['Age'].isna().sum())\\n\\\n",
        "\\n\\\n",
        "# Eliminar las filas con valores faltantes antes de crear el boxplot\\n\\\n",
        "data1_clean = data1.dropna(subset=['Age'])\\n\\\n",
        "\\n\\\n",
        "# Calcular la media, mediana y cuartiles de la variable Age\\n\\\n",
        "age_mean = data1_clean['Age'].mean()\\n\\\n",
        "age_median = data1_clean['Age'].median()\\n\\\n",
        "age_q1 = data1_clean['Age'].quantile(0.25)\\n\\\n",
        "age_q3 = data1_clean['Age'].quantile(0.75)\\n\\\n",
        "\\n\\\n",
        "# Crear el boxplot para la variable Age en el conjunto de datos limpio\\n\\\n",
        "box = plt.boxplot(data1_clean['Age'])\\n\\\n",
        "\\n\\\n",
        "# Agregar líneas para la media y la mediana\\n\\\n",
        "plt.axhline(y=age_mean, color='r', linestyle='-')\\n\\\n",
        "plt.axhline(y=age_median, color='b', linestyle='-')\\n\\\n",
        "\\n\\\n",
        "# Establecer el título del gráfico\\n\\\n",
        "plt.title('Boxplot of Age in Titanic Data1')\\n\\\n",
        "\\n\\\n",
        "# Etiquetar el eje x como Age\\n\\\n",
        "plt.xlabel('Age')\\n\\\n",
        "\\n\\\n",
        "# Mostrar el gráfico en la pantalla\\n\\\n",
        "plt.show()\\n\\\n",
        "\\n\\\n",
        "# Verificar si la distribución es simétrica, sesgada a la izquierda o sesgada a la derecha\\n\\\n",
        "print ('El código utiliza la relación entre la media y la mediana para determinar si la distribución está sesgada a la izquierda o a la derecha.') \\n\\\n",
        "print ('Si la media es mayor que la mediana, se considera que la distribución está sesgada a la derecha, y si la media es menor que la mediana,') \\n\\\n",
        "print ('se considera que la distribución está sesgada a la izquierda.')\\n\\\n",
        "print(' ')\\n\\\n",
        "\\n\\\n",
        "# print('\\033[91m' + 'texto' + '\\033[0m')le cambia el color a la respuesta a rojo, \\033 se utilizan para cambiar el formato del texto en la consola\\n\\\n",
        "#\\033[91m El número 91 indica que se utilizará el color rojo el [inicia el enunciado\\033[0m se utiliza para restablecer el formato del texto a su valor predeterminado en la consola\\n\\\n",
        "# quitar el espacio entre el \\ y 0 en \\033 \\n\\\n",
        "if age_mean > age_median:\\n\\\n",
        "    print('\\ 033[91m' + 'La distribución está sesgada a la derecha' + '\\ 033[0m')\\n\\\n",
        "elif age_mean < age_median:\\n\\\n",
        "    print('\\ 033[91m' + 'La distribución está sesgada a la izquierda' + '\\ 033[0m')\\n\\\n",
        "else:\\n\\\n",
        "    print('La distribución es simétrica')\\n\\\n",
        "\\n\\\n",
        "# Verificar si los valores están concentrados cerca de la mediana o si están dispersos \\n\\\n",
        "# print('\\033[91m' + 'texto' + '\\033[0m')le cambia el color a la respuesta a rojo, \\033 se utilizan para cambiar el formato del texto en la consola\\n\\\n",
        "#\\033[91m El número 91 indica que se utilizará el color rojo el [inicia el enunciado\\033[0m se utiliza para restablecer el formato del texto a su valor predeterminado en la consola\\n\\\n",
        "print(' ')\\n\\\n",
        "print ('Para determinar si los valores están dispersos se compara el rango intercuartil (IQR) distancia entre el primer cuartil (Q1) y el tercer cuartil (Q3)')\\n\\\n",
        "print ('q3 menos q1 (Q3 - Q1) con la mediana.Si el IQR  es menor que la mediana,se considera que los valores están concentrados cerca de la mediana')\\n\\\n",
        "print ('si el IQR es mayor que la mediana, se considera que los valores están dispersos.')\\n\\\n",
        "print(' ')\\n\\\n",
        "if age_q3 - age_q1 < age_median:\\n\\\n",
        "    print('\\ 033[91m' + 'Los valores están muy concentrados cerca de la mediana' + '\\ 033[0m')\\n\\\n",
        "else:\\n\\\n",
        "    print('\\ 033[91m' + 'Los valores están dispersos' + '\\ 033[0m')\\n\\\n",
        "\\n\\\n",
        "# Dar información de cómo se lee el boxplot\\n\\\n",
        "print(' ')\\n\\\n",
        "print('La línea inferior es el mínimo, la línea superior es el máximo, en la caja hay 3 datos importantes: Q1 inicio de la caja, Q2 mediana, Q3 fin de la caja,') \\n\\\n",
        "print('la media es el valor que se obtiene al dividir la suma de un conglomerado de números entre la cantidad de ellos y por último,')\\n\\\n",
        "print('los outliers son datos que están fuera de medición por ser extremos y no son consistentes con el resto.')\\n\\\n",
        "\\n\\\n",
        "\\n\\\n",
        "# Imprimir los valores de los bigotes, la caja, la mediana y los outliers\\n\\\n",
        "# cambiar f'\\ y }') por comillas dobles y quitarle el espacio a \\ n \\n\\\n",
        "print(' ')\\n\\\n",
        "print(f'Bigote inferior: {box['whiskers'][0].get_ydata()[1]}')\\n\\\n",
        "print(f'Bigote superior: {box['whiskers'][1].get_ydata()[1]}')\\n\\\n",
        "print(f'Caja: {box['boxes'][0].get_ydata()}')\\n\\\n",
        "print(f'Mediana: {box['medians'][0].get_ydata()[0]}')\\n\\\n",
        "print(f'Outliers: {box['fliers'][0].get_ydata()}')\\n\\\n",
        "\\n\\\n",
        "# Imprimir los valores de la media, mediana y cuartiles\\n\\\n",
        "print(f'Media: {age_mean:.2f}')\\n\\\n",
        "print(f'Mediana: {age_median}')\\n\\\n",
        "print(f'Cuartil 1: {age_q1}')\\n\\\n",
        "print(f'Cuartil 3: {age_q3}')\"\n",
        "print (boxplot)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXxWUpayGFyr",
        "outputId": "0c8fddfc-7448-4839-b1d7-9774752ac9f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LEER BIEN LAS INSTRUCCIONES DE LA ULTIMA LINEA quitar el espacio entre el \\ y 0 en \\ 033 en lineas 42, 44, 57, 59 para plotear en rojo \n",
            "import matplotlib.pyplot as plt \n",
            "\n",
            "# Verificar si hay valores faltantes en la columna Age\n",
            "print('valores faltantes: ', data1['Age'].isna().sum())\n",
            "\n",
            "# Eliminar las filas con valores faltantes antes de crear el boxplot\n",
            "data1_clean = data1.dropna(subset=['Age'])\n",
            "\n",
            "# Calcular la media, mediana y cuartiles de la variable Age\n",
            "age_mean = data1_clean['Age'].mean()\n",
            "age_median = data1_clean['Age'].median()\n",
            "age_q1 = data1_clean['Age'].quantile(0.25)\n",
            "age_q3 = data1_clean['Age'].quantile(0.75)\n",
            "\n",
            "# Crear el boxplot para la variable Age en el conjunto de datos limpio\n",
            "box = plt.boxplot(data1_clean['Age'])\n",
            "\n",
            "# Agregar líneas para la media y la mediana\n",
            "plt.axhline(y=age_mean, color='r', linestyle='-')\n",
            "plt.axhline(y=age_median, color='b', linestyle='-')\n",
            "\n",
            "# Establecer el título del gráfico\n",
            "plt.title('Boxplot of Age in Titanic Data1')\n",
            "\n",
            "# Etiquetar el eje x como Age\n",
            "plt.xlabel('Age')\n",
            "\n",
            "# Mostrar el gráfico en la pantalla\n",
            "plt.show()\n",
            "\n",
            "# Verificar si la distribución es simétrica, sesgada a la izquierda o sesgada a la derecha\n",
            "print ('El código utiliza la relación entre la media y la mediana para determinar si la distribución está sesgada a la izquierda o a la derecha.') \n",
            "print ('Si la media es mayor que la mediana, se considera que la distribución está sesgada a la derecha, y si la media es menor que la mediana,') \n",
            "print ('se considera que la distribución está sesgada a la izquierda.')\n",
            "print(' ')\n",
            "\n",
            "# print('\u001b[91m' + 'texto' + '\u001b[0m')le cambia el color a la respuesta a rojo, \u001b se utilizan para cambiar el formato del texto en la consola\n",
            "#\u001b[91m El número 91 indica que se utilizará el color rojo el [inicia el enunciado\u001b[0m se utiliza para restablecer el formato del texto a su valor predeterminado en la consola\n",
            "# quitar el espacio entre el \\ y 0 en \u001b \n",
            "if age_mean > age_median:\n",
            "    print('\\ 033[91m' + 'La distribución está sesgada a la derecha' + '\\ 033[0m')\n",
            "elif age_mean < age_median:\n",
            "    print('\\ 033[91m' + 'La distribución está sesgada a la izquierda' + '\\ 033[0m')\n",
            "else:\n",
            "    print('La distribución es simétrica')\n",
            "\n",
            "# Verificar si los valores están concentrados cerca de la mediana o si están dispersos \n",
            "# print('\u001b[91m' + 'texto' + '\u001b[0m')le cambia el color a la respuesta a rojo, \u001b se utilizan para cambiar el formato del texto en la consola\n",
            "#\u001b[91m El número 91 indica que se utilizará el color rojo el [inicia el enunciado\u001b[0m se utiliza para restablecer el formato del texto a su valor predeterminado en la consola\n",
            "print(' ')\n",
            "print ('Para determinar si los valores están dispersos se compara el rango intercuartil (IQR) distancia entre el primer cuartil (Q1) y el tercer cuartil (Q3)')\n",
            "print ('q3 menos q1 (Q3 - Q1) con la mediana.Si el IQR  es menor que la mediana,se considera que los valores están concentrados cerca de la mediana')\n",
            "print ('si el IQR es mayor que la mediana, se considera que los valores están dispersos.')\n",
            "print(' ')\n",
            "if age_q3 - age_q1 < age_median:\n",
            "    print('\\ 033[91m' + 'Los valores están muy concentrados cerca de la mediana' + '\\ 033[0m')\n",
            "else:\n",
            "    print('\\ 033[91m' + 'Los valores están dispersos' + '\\ 033[0m')\n",
            "\n",
            "# Dar información de cómo se lee el boxplot\n",
            "print(' ')\n",
            "print('La línea inferior es el mínimo, la línea superior es el máximo, en la caja hay 3 datos importantes: Q1 inicio de la caja, Q2 mediana, Q3 fin de la caja,') \n",
            "print('la media es el valor que se obtiene al dividir la suma de un conglomerado de números entre la cantidad de ellos y por último,')\n",
            "print('los outliers son datos que están fuera de medición por ser extremos y no son consistentes con el resto.')\n",
            "\n",
            "\n",
            "# Imprimir los valores de los bigotes, la caja, la mediana y los outliers\n",
            "# cambiar f'\\ y }') por comillas dobles y quitarle el espacio a \\ n \n",
            "print(' ')\n",
            "print(f'Bigote inferior: {box['whiskers'][0].get_ydata()[1]}')\n",
            "print(f'Bigote superior: {box['whiskers'][1].get_ydata()[1]}')\n",
            "print(f'Caja: {box['boxes'][0].get_ydata()}')\n",
            "print(f'Mediana: {box['medians'][0].get_ydata()[0]}')\n",
            "print(f'Outliers: {box['fliers'][0].get_ydata()}')\n",
            "\n",
            "# Imprimir los valores de la media, mediana y cuartiles\n",
            "print(f'Media: {age_mean:.2f}')\n",
            "print(f'Mediana: {age_median}')\n",
            "print(f'Cuartil 1: {age_q1}')\n",
            "print(f'Cuartil 3: {age_q3}')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split datasets\n",
        "1. **train_test_split** : dividir un conjunto de datos en conjuntos de entrenamiento y prueba para evaluar la capacidad de generalización de un modelo.(**para problemas pequeños y medianos**)\n",
        "2. **ShuffleSplit** : realiza una división aleatoria múltiple de los datos en subconjuntos de entrenamiento y prueba y los resultados se promedian. (**para problemas con conjuntos de datos más grandes**).\n",
        "3. \n",
        "4. \n",
        "5. \n"
      ],
      "metadata": {
        "id": "YRyBZpHgN6-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Normalization :  la normalización ayuda a evitar que las características con grandes valores dominen las características con valores pequeños y a garantizar que las características estén en la misma escala.\n",
        "\n",
        "### 1. **completar_nan** : imputaciones (se recomienda imputar antes de normalizar)\n",
        "\n",
        "**Las imputaciones numéricas son:**\n",
        "\n",
        "*   Imputación con la mediana (imputar_mediana)\n",
        "*   Imputación con la media (imputar_media)\n",
        "*   Imputación con valores aleatorios entre Q1 y Q3 (imputar_q1_q3_random)\n",
        "*   Imputación con K-vecinos cercanos (imputar_knn)\n",
        "*   Imputación con regresión lineal (Imputacion_con_regresion_lineal)modelo de regresión para predecir los valores faltantes basados en las variables disponibles.\n",
        "*   Imputación con valores extremos (Imputacion_valores_extremos)se reemplazan los valores faltantes con valores extremos (por ejemplo, el valor mínimo o máximo de la variable) para representar una situación en la que los datos faltantes pueden ser valores atípicos.\n",
        "*   Imputación anterior o posterior (Imputacion_anterior_posterior)  se reemplazan los valores faltantes con el valor anterior o posterior de la misma variable.\n",
        "\n",
        "**Las imputaciones categóricas son:**\n",
        "\n",
        "*   Imputación con la moda (imputar_moda) se reemplazan los valores faltantes con la moda o valor más frecuente de la variable.\n",
        "*   Imputación con regresión logística (Imputacion_regresion_logistica) modelo de regresión logística para predecir los valores faltantes de una variable categórica, a partir de otras variables.\n",
        "*   Imputación múltiple (Imputacion_multiple) se utiliza un modelo estadístico para generar múltiples valores posibles para los valores faltantes, a partir de la información disponible en las demás variables, y se selecciona uno de ellos como valor imputado.\n",
        "\n",
        "\n",
        "### 2. **normalize** : Normalizar es un proceso en el que se ajustan los valores de una variable para que estén dentro de un rango específico, a menudo con el objetivo de hacer que los datos sean más comparables o para mejorar el rendimiento de un modelo de aprendizaje automático.\n",
        "\n",
        "La normalización es una técnica común en el preprocesamiento de datos y puede tomar muchas formas. En el caso de la normalización min-max, los valores se ajustan a un rango específico, a menudo entre 0 y 1, mediante la siguiente fórmula:\n",
        "\n",
        "x_norm = (x - min(x)) / (max(x) - min(x))\n",
        "\n",
        "donde x es un valor de la variable original, min(x) es el valor mínimo de la variable, max(x) es el valor máximo de la variable y x_norm es el valor normalizado.\n",
        "\n",
        "Por otro lado, la normalización estándar o z-score ajusta los valores para que tengan una media de cero y una desviación estándar de uno mediante la siguiente fórmula:\n",
        "\n",
        "x_norm = (x - mean(x)) / std(x)\n",
        "\n",
        "donde x es un valor de la variable original, mean(x) es la media de la variable y std(x) es la desviación estándar de la variable, y x_norm es el valor normalizado.\n",
        "\n",
        "**minmaxscaler y standard scaler**\n",
        "\n",
        "**Se debe usar MinMaxScaler** cuando se necesita ajustar el rango de valores de las características en un rango específico, por ejemplo, entre 0 y 1. Esto es útil cuando se trabaja con algoritmos que se basan en la distancia euclidiana, como el K-vecinos más cercanos (K-NN) o la regresión lineal.\n",
        "\n",
        "**se debe usar StandardScaler** cuando se necesita ajustar la distribución de valores de las características a una distribución normal con una media de cero y una desviación estándar de uno. Esto es útil cuando se trabaja con algoritmos basados en la magnitud de las características, como la regresión logística o las redes neuronales.\n",
        "\n",
        "En ambos casos, primero se importa la clase necesaria de sklearn.preprocessing Luego, se ajusta y se transforma la columna Age utilizando el método fit_transform() del objeto creado anteriormente. Finalmente, se agrega la columna normalizada al conjunto de datos mediante la asignación de los valores normalizados a una nueva columna del conjunto de datos.\n",
        "\n",
        "**Normalización L1 y L2:**\n",
        "La normalización L1 y L2 son métodos de normalización que ajustan los valores de las características (features) en un rango determinado. La normalización L1 ajusta los valores de las características para que la suma de los valores absolutos sea igual a 1, mientras que la normalización L2 ajusta los valores para que la suma de los cuadrados de los valores sea igual a 1.\n",
        "La normalización L1 produce una matriz donde la suma de los valores absolutos de cada fila es igual a 1. La normalización L2 produce una matriz donde la suma de los cuadrados de cada fila es igual a 1.\n",
        "\n",
        "**Normalización por valor máximo absoluto (MaxAbs):**\n",
        "La normalización por valor máximo absoluto escala los valores de las características dividiendo cada valor por el valor máximo absoluto. El resultado es que los valores se ajustan en el rango [-1, 1].\n",
        "Los valores se ajustan en el rango [-1, 1], donde el valor máximo absoluto es 9. La normalización por valor máximo absoluto divide cada valor por el valor máximo absoluto.\n",
        "\n",
        "**Normalización por cuartiles (RobustScaler):**\n",
        "La normalización por cuartiles escala los valores de las características dividiendo cada valor por el rango intercuartil (IQR). El rango intercuartil es la diferencia entre el tercer cuartil (Q3) y el primer cuartil (Q1). La normalización por cuartiles (RobustScaler) es útil cuando los datos contienen valores atípicos (outliers) y se desea minimizar su influencia en la escala de los datos.\n",
        "Es importante tener en cuenta que la normalización por cuartiles es más adecuada para datos que contienen valores atípicos y puede no ser tan efectiva para datos con una distribución más uniforme. En esos casos, otros métodos de normalización, como MinMaxScaler o StandardScaler, pueden ser más adecuados.La normalización por cuartiles (RobustScaler) escala los valores de las características dividiendo cada valor por el rango intercuartil (IQR). El rango intercuartil es la diferencia entre el tercer cuartil (Q3) y el primer cuartil (Q1).\n",
        "\n",
        "En el código, primero se carga un conjunto de datos con características numéricas. Luego se crea una instancia del RobustScaler y se utiliza para escalar los datos. Después se convierten los datos escalados de vuelta a un dataframe y se imprimen las estadísticas de los datos escalados.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TQcO5jPx1MbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imputar_mediana = \" median = data2.Age.median() \\n\\\n",
        "data2['Age'] = data2['Age'].fillna(median)\\n\\\n",
        "data2.head()\"\n",
        "print (imputar_mediana)\n",
        "\n",
        "imputar_media = \"mean = data2.Age.mean()\\n\\\n",
        "data2['Age'] = data2['Age'].fillna(mean)\\n\\\n",
        "data2.head()\"\n",
        "print (imputar_media)\n",
        "\n",
        "imputar_moda = \"from sklearn.impute import SimpleImputer\\n\\\n",
        "\\n\\\n",
        "# Cargar datos\\n\\\n",
        "data = pd.read_csv('data.csv')\\n\\\n",
        "\\n\\\n",
        "# Imputar con moda\\n\\\n",
        "imputer = SimpleImputer(strategy='most_frequent')\\n\\\n",
        "data['columna'] = imputer.fit_transform(data[['columna']])\"\n",
        "print (imputar_moda)\n",
        "\n",
        "imputar_knn = \"from sklearn.impute import KNNImputer\\n\\\n",
        "\\n\\\n",
        "# Cargar datos\\n\\\n",
        "data = pd.read_csv('data.csv')\\n\\\n",
        "\\n\\\n",
        "# Imputar con k-vecinos cercanos\\n\\\n",
        "imputer = KNNImputer(n_neighbors=3)\\n\\\n",
        "data_imputed = imputer.fit_transform(data)\"\n",
        "print (imputar_knn)\n",
        "\n",
        "imputar_q1_q3_random = \"import numpy as np\\n\\\n",
        "\\n\\\n",
        "# Calcular los cuartiles\\n\\\n",
        "q1, q3 = np.percentile(data['Age'].dropna(), [25, 75])\\n\\\n",
        "\\n\\\n",
        "# Imputar valores aleatorios entre q1 y q3\\n\\\n",
        "data['Age'] = data['Age'].apply(lambda x: np.random.uniform(q1, q3) if np.isnan(x) else x)\\n\\\n",
        "#calcula los cuartiles Q1 y Q3 de la variable numérica Age. Luego, utiliza la función apply  para aplicar una función lambda a cada valor de la variable.\\n\\\n",
        "#La función lambda comprueba si el valor es NaN y, en ese caso, genera un valor aleatorio entre Q1 y Q3 utilizando la función random.uniform de NumPy.\\n\\\n",
        "#De lo contrario, simplemente devuelve el valor original.\"\n",
        "print (imputar_q1_q3_random)\n",
        "\n",
        "Imputacion_con_regresion_lineal = \"from sklearn.linear_model import LinearRegression\\n\\\n",
        "from sklearn.impute import SimpleImputer\\n\\\n",
        "\\n\\\n",
        "# Cargar datos\\n\\\n",
        "data = pd.read_csv('data.csv')\\n\\\n",
        "\\n\\\n",
        "# Separar datos completos e incompletos\\n\\\n",
        "data_complete = data.dropna()\\n\\\n",
        "data_incomplete = data[data.isnull().any(axis=1)]\\n\\\n",
        "\\n\\\n",
        "# Entrenar modelo de regresión\\n\\\n",
        "reg = LinearRegression()\\n\\\n",
        "reg.fit(data_complete[['variable_1', 'variable_2']], data_complete['variable_faltante'])\\n\\\n",
        "\\n\\\n",
        "# Imputar valores faltantes\\n\\\n",
        "imputer = SimpleImputer(strategy='constant', fill_value=0)\\n\\\n",
        "imputed_values = reg.predict(data_incomplete[['variable_1', 'variable_2']])\\n\\\n",
        "data_incomplete['variable_faltante'] = imputed_values\\n\\\n",
        "data = pd.concat([data_complete, data_incomplete], axis=0)\"\n",
        "print (Imputacion_con_regresion_lineal)\n",
        "\n",
        "Imputacion_multiple = \"from sklearn.experimental import enable_iterative_imputer\\n\\\n",
        "from sklearn.impute import IterativeImputer\\n\\\n",
        "\\n\\\n",
        "# Cargar datos\\n\\\n",
        "data = pd.read_csv('data.csv')\\n\\\n",
        "\\n\\\n",
        "# Imputar valores faltantes\\n\\\n",
        "imputer = IterativeImputer()\\n\\\n",
        "data_imputed = imputer.fit_transform(data)\"\n",
        "print (Imputacion_multiple)\n",
        "\n",
        "Imputacion_valores_extremos = \"# Cargar datos\\n\\\n",
        "data = pd.read_csv('data.csv')\\n\\\n",
        "\\n\\\n",
        "# Imputar valores faltantes con el valor mínimo\\n\\\n",
        "data['variable_faltante'] = data['variable_faltante'].fillna(data['variable_faltante'].min())\\n\\\n",
        "\\n\\\n",
        "# Imputar valores faltantes con el valor máximo\\n\\\n",
        "data['variable_faltante'] = data['variable_faltante'].fillna(data['variable_faltante'].max())\"\n",
        "print (Imputacion_valores_extremos)\n",
        "\n",
        "Imputacion_anterior_posterior = \"# Cargar datos\\n\\\n",
        "data = pd.read_csv('data.csv')\\n\\\n",
        "\\n\\\n",
        "# Imputar con valor anterior o posterior\\n\\\n",
        "data['columna'] = data['columna'].fillna(method='ffill') # Para imputar con el valor anterior\\n\\\n",
        "data['columna'] = data['columna'].fillna(method='bfill') # Para imputar con el valor posterior\"\n",
        "print (Imputacion_anterior_posterior)\n",
        "\n",
        "Imputacion_regresion_logistica = \"from sklearn.linear_model import LogisticRegression\\n\\\n",
        "\\n\\\n",
        "# Cargar datos\\n\\\n",
        "data = pd.read_csv('data.csv')\\n\\\n",
        "\\n\\\n",
        "# Imputar con regresión logística\\n\\\n",
        "X = data.drop('columna', axis=1)\\n\\\n",
        "y = data['columna']\\n\\\n",
        "imputer = LogisticRegression()\\n\\\n",
        "imputer.fit(X, y)\\n\\\n",
        "data['columna'] = imputer.predict(X)\"\n",
        "print(Imputacion_regresion_logistica)\n",
        "\n",
        "Imputacion_multiple = \"from sklearn.experimental import enable_iterative_imputer\\n\\\n",
        "from sklearn.impute import IterativeImputer\\n\\\n",
        "\\n\\\n",
        "# Cargar datos\\n\\\n",
        "data = pd.read_csv('data.csv')\\n\\\n",
        "\\n\\\n",
        "# Imputar con imputación múltiple\\n\\\n",
        "imputer = IterativeImputer()\\n\\\n",
        "data_imputed = imputer.fit_transform(data)\"\n",
        "print (Imputacion_multiple)"
      ],
      "metadata": {
        "id": "2VpcuylR1L2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MinMaxScaler = \"from sklearn.preprocessing import MinMaxScaler \\n\\\n",
        "minmax_scaler = MinMaxScaler() #CREAR LA INSTANCIA DE MINMAXSCALER (llamar las propiedades de minmaxscaler y almacenarlas en el objeto)\\n\\\n",
        "# For MinMax Scaler:\\n\\\n",
        "normalized_age_minmax = minmax_scaler.fit_transform(data2[['Age']]) #ajusta el rango de valores de la columna Age para que esté entre 0 y 1. se encuentra \\n\\\n",
        "#el valor mínimo y máximo de la columna y se ajusta cada valor  para que esté en ese rango. se utiliza el método fit_transform() para ajustar los valores y transformarlos al mismo tiempo.\\n\\\n",
        "#Add the normalized column(s) to the dataset:\\n\\\n",
        "data2['Age_MinMax'] = normalized_age_minmax\"\n",
        "print (MinMaxScaler)\n",
        "\n",
        "StandardScaler = \"from sklearn.preprocessing import StandardScaler\\n\\\n",
        "standard_scaler = StandardScaler() #CREAR LA INSTANCIA DE STANDARDSCALER (llamar las propiedades de standardscaler y almacenarlas en el objeto)\\n\\\n",
        "# For Standard Scaler:\\n\\\n",
        "normalized_age_standard = standard_scaler.fit_transform(data2[['Age']]) #se ajusta la distribución de valores de Age para que tengan una media de cero\\n\\\n",
        "# y una desviación estándar de uno. Es decir, se encuentra la media y la desviación estándar de la columna y se ajusta cada valor de la columna \\n\\\n",
        "#se utiliza el método fit_transform() para ajustar los valores y transformarlos al mismo tiempo.\\n\\\n",
        "#Add the normalized column(s) to the dataset:\\n\\\n",
        "data2['Age_Standard'] = normalized_age_standard\"\n",
        "print (StandardScaler)\n",
        "\n",
        "l1_l2 = \"from sklearn.preprocessing import normalize\\n\\\n",
        "import numpy as np\\n\\\n",
        "\\n\\\n",
        "# Ejemplo de datos con características numéricas\\n\\\n",
        "data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\\n\\\n",
        "\\n\\\n",
        "# Normalización L1\\n\\\n",
        "data_normalized_l1 = normalize(data, norm='l1')\\n\\\n",
        "print('Data normalized using L1 normalization:\\n', data_normalized_l1)\\n\\\n",
        "\\n\\\n",
        "# Normalización L2\\n\\\n",
        "data_normalized_l2 = normalize(data, norm='l2')\\n\\\n",
        "print('\\nData normalized using L2 normalization:\\n', data_normalized_l2)\"\n",
        "print(l1_l2)\n",
        "\n",
        "MaxAbsoluto = \"from sklearn.preprocessing import MaxAbsScaler\\n\\\n",
        "\\n\\\n",
        "# Ejemplo de datos con características numéricas\\n\\\n",
        "data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\\n\\\n",
        "\\n\\\n",
        "# Normalización por valor máximo absoluto\\n\\\n",
        "maxabs_scaler = MaxAbsScaler()\\n\\\n",
        "data_normalized_maxabs = maxabs_scaler.fit_transform(data)\\n\\\n",
        "print('Data normalized using MaxAbs normalization:\\n', data_normalized_maxabs)\"\n",
        "print(MaxAbsoluto)\n",
        "\n",
        "RobustScaler_quartiles = \"from sklearn.preprocessing import RobustScaler\\n\\\n",
        "import pandas as pd\\n\\\n",
        "\\n\\\n",
        "# cargar datos\\n\\\n",
        "data = pd.read_csv('datos.csv')\\n\\\n",
        "\\n\\\n",
        "# crear instancia del RobustScaler\\n\\\n",
        "scaler = RobustScaler()\\n\\\n",
        "\\n\\\n",
        "# escalar los datos\\n\\\n",
        "data_scaled = scaler.fit_transform(data)\\n\\\n",
        "\\n\\\n",
        "# convertir los datos escalados de nuevo a un dataframe\\n\\\n",
        "data_scaled = pd.DataFrame(data_scaled, columns=data.columns)\\n\\\n",
        "\\n\\\n",
        "# imprimir las estadísticas de los datos escalados\\n\\\n",
        "print('Estadísticas de los datos escalados:')\\n\\\n",
        "print(data_scaled.describe())\"\n",
        "print (RobustScaler_quartiles)\n"
      ],
      "metadata": {
        "id": "by6VqUcNN0Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Categorical Encoding\n",
        "\n",
        "es una técnica utilizada en el preprocesamiento de datos para convertir variables categóricas o de texto en variables numéricas, que puedan ser utilizadas por los algoritmos de aprendizaje automático.\n",
        "\n",
        "Las variables categóricas son variables que tienen un número limitado de valores posibles y se dividen en dos tipos: nominales y ordinales. Las variables nominales no tienen un orden específico, como el género o la ciudad de origen. Por otro lado, las variables ordinales sí tienen un orden específico, como la calificación escolar o el nivel de educación.\n",
        "\n",
        "Hay varios métodos comunes de codificación de variables categóricas, entre ellos:\n",
        "\n",
        "One-Hot Encoding: Este método convierte cada valor único de la variable categórica en una nueva columna binaria (0 o 1) y se usa para variables nominales y ordinales. Este transformador codifica las variables categóricas mediante el uso de un esquema de codificación one-hot (también conocido como 'uno-de-K' o 'dummy'), creando una columna binaria para cada categoría. El resultado es una matriz dispersa o un array denso, dependiendo del parámetro \n",
        "\n",
        "Label Encoding: Este método convierte cada valor único de la variable categórica en un número entero único y se usa para variables ordinales.\n",
        "\n",
        "Binary Encoding: Este método convierte cada valor único de la variable categórica en su representación binaria y se usa para variables nominales y ordinales.\n",
        "\n",
        "Count Encoding: Este método asigna a cada valor categórico el número de veces que aparece en los datos y se usa para variables nominales y ordinales.\n",
        "\n",
        "Target Encoding: Este método utiliza la variable objetivo para codificar cada valor único de la variable categórica y se usa para variables nominales y ordinales.\n",
        "Es importante tener en cuenta que la elección del método de codificación depende del tipo de variable categórica, su cardinalidad (número de valores únicos), la cantidad de datos y el modelo de aprendizaje automático utilizado.\n",
        "\n",
        "One-Hot Encoding: Se utiliza tanto para variables categóricas nominales como ordinales.\n",
        "Label Encoding: Se utiliza para variables categóricas ordinales.\n",
        "Binary Encoding: Se utiliza tanto para variables categóricas nominales como ordinales, pero es especialmente útil para variables con alta cardinalidad (número de valores únicos).\n",
        "Count Encoding: Se utiliza tanto para variables categóricas nominales como ordinales, pero es especialmente útil para variables con baja cardinalidad.\n",
        "Target Encoding: Se utiliza tanto para variables categóricas nominales como ordinales, pero es especialmente útil cuando la variable objetivo está altamente relacionada con la variable categórica."
      ],
      "metadata": {
        "id": "KaptFyT7Fh3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-Hot Encoding\n",
        "El One-Hot Encoding se utiliza para convertir variables categóricas en columnas binarias 0 o 1. Cada columna binaria representa una categoría única de la variable original.\n",
        "\n",
        "Algunos parámetros importantes de este transformador son:\n",
        "\n",
        "categories: permite especificar las categorías manualmente o determinarlas automáticamente a partir de los datos de entrenamiento.\n",
        "\n",
        "drop: permite especificar una metodología para eliminar una de las categorías por variable. Esto es útil en situaciones donde las variables perfectamente colineales causan problemas, como al alimentar los datos resultantes en un modelo de regresión lineal no regularizado.\n",
        "\n",
        "sparse_output: permite especificar si el resultado debe ser una matriz dispersa o un array denso.\n",
        "El transformador cuenta con métodos como fit(), que se utiliza para ajustar el transformador a los datos de entrada.\n",
        "\n",
        "Una vez que el transformador ha sido ajustado a los datos de entrada utilizando el método fit(), se puede utilizar el método transform() para transformar los datos de entrada en una matriz numérica de codificación one-hot.\n",
        "\n",
        "El método fit_transform() combina ambos métodos, ajustando el transformador a los datos de entrada y transformándolos en una matriz codificada one-hot al mismo tiempo. También hay un método inverse_transform() para revertir la transformación y obtener los datos originales.\n",
        "\n",
        "\n",
        "Ejemplo:\n",
        "Supongamos que tenemos una columna de género con tres valores únicos: \"masculino\", \"femenino\" y \"no binario\". Utilizaremos One-Hot Encoding para convertir esta variable categórica en columnas binarias 0 o 1.\n",
        "\n",
        "ID\tGénero\n",
        "1\tmasculino\n",
        "2\tfemenino\n",
        "3\tno binario\n",
        "4\tmasculino\n",
        "5\tfemenino\n"
      ],
      "metadata": {
        "id": "77RFYhYiHNGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "data = pd.read_csv(\"datos.csv\")\n",
        "\n",
        "encoder = OneHotEncoder()\n",
        "encoded_data = encoder.fit_transform(data[[\"Género\"]]).toarray()\n",
        "\n",
        "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names([\"Género\"]))\n",
        "result = pd.concat([data, encoded_df], axis=1)\n"
      ],
      "metadata": {
        "id": "9Ob5udHNGuXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ejemplo 2:"
      ],
      "metadata": {
        "id": "WLTi0UaJbCDL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eCgzCSojbBrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Label Encoding\n",
        "El Label Encoding se utiliza para transformar variables ordinales en números enteros únicos.\n",
        "\n",
        "Ejemplo:\n",
        "Supongamos que tenemos una columna de tallas de ropa con valores ordinales: \"XS\", \"S\", \"M\", \"L\", \"XL\". Utilizaremos Label Encoding para transformar esta variable en números enteros únicos.\n",
        "\n",
        "ID\tTalla\n",
        "1\tXS\n",
        "2\tS\n",
        "3\tM\n",
        "4\tL\n",
        "5\tXL\n"
      ],
      "metadata": {
        "id": "WP7twp31HSuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "data = pd.read_csv(\"datos.csv\")\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "data[\"Talla_encoded\"] = encoder.fit_transform(data[\"Talla\"])\n"
      ],
      "metadata": {
        "id": "faRWACdwHWmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Binary Encoding\n",
        "El Binary Encoding se utiliza para convertir variables categóricas en su representación binaria.\n",
        "\n",
        "Ejemplo:\n",
        "Supongamos que tenemos una columna de países con 20 valores únicos. Utilizaremos Binary Encoding para convertir esta variable categórica en su representación binaria.\n",
        "\n",
        "ID\tPaís\n",
        "1\tEspaña\n",
        "2\tItalia\n",
        "3\tEspaña\n",
        "4\tEstados Unidos\n",
        "5\tItalia\n"
      ],
      "metadata": {
        "id": "XR1IdvSzHYba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import category_encoders as ce\n",
        "\n",
        "data = pd.read_csv(\"datos.csv\")\n",
        "\n",
        "encoder = ce.BinaryEncoder(cols=[\"País\"])\n",
        "data_encoded = encoder.fit_transform(data)\n"
      ],
      "metadata": {
        "id": "qMM0hitkHdIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Count Encoding\n",
        "El Count Encoding se utiliza para codificar las categorías en función del número de veces que aparecen en los datos.\n",
        "\n",
        "Ejemplo:\n",
        "Supongamos que tenemos una columna de colores con 10 valores únicos. Utilizaremos Count Encoding para codificar cada color en función del número de veces que aparece en los datos.\n",
        "\n",
        "ID\tColor\n",
        "1\tRojo\n",
        "2\tAzul\n",
        "3\tVerde\n",
        "4\tRojo\n",
        "5\tAmarillo\n"
      ],
      "metadata": {
        "id": "qsF3wVIjHhID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import category_encoders as ce\n",
        "\n",
        "data = pd.read_csv(\"datos.csv\")\n",
        "\n",
        "encoder = ce.CountEncoder(cols=[\"Color\"])\n",
        "data_encoded = encoder.fit_transform(data)\n"
      ],
      "metadata": {
        "id": "l8L-6gURHi2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Target Encoding\n",
        "El Target Encoding se utiliza para codificar las categorías en función de la variable objetivo.\n",
        "\n",
        "Ejemplo:\n",
        "Supongamos que tenemos una columna de ciudades con 20 valores únicos y queremos predecir el precio de la vivienda en cada ciudad. Utilizaremos Target Encoding para codificar cada ciudad en función del precio medio de la vivienda en esa ciudad.\n",
        "\n",
        "ID\tCiudad\tPrecio\n",
        "1\tMadrid\t500000\n",
        "2\tBarcelona\t450000\n",
        "3\tValencia\t300000\n",
        "4\tMadrid\t550000\n",
        "5\tBarcelona\t400000\n"
      ],
      "metadata": {
        "id": "qQys6dZ1Hwg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import category_encoders as ce\n",
        "\n",
        "data = pd.read_csv(\"datos.csv\")\n",
        "\n",
        "encoder = ce.TargetEncoder(cols=[\"Ciudad\"])\n",
        "data_encoded = encoder.fit_transform(data[\"Ciudad\"], data[\"Precio\"])\n",
        "result = pd.concat([data.drop(columns=[\"Ciudad\"]), data_encoded], axis=1)\n"
      ],
      "metadata": {
        "id": "VcupVrhPH0A7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}